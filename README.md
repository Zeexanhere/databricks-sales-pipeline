# ğŸ­ Databricks Sales Analytics Pipeline

A complete end-to-end data engineering pipeline built on **Databricks Community Edition** using the **Medallion Architecture** (Bronze â†’ Silver â†’ Gold). This project covers all core Databricks concepts including Delta Lake, PySpark, SQL, Workflows, Dashboards, and Git Integration.

---

## ğŸ“Œ Project Overview

| Component | Details |
|-----------|---------|
| **Platform** | Databricks Community Edition |
| **Language** | Python (PySpark), SQL |
| **Dataset** | Databricks Built-in `retail-org/sales_orders` |
| **Architecture** | Medallion (Bronze â†’ Silver â†’ Gold) |
| **Storage Format** | Delta Lake |
| **Orchestration** | Databricks Workflows |
| **Version Control** | GitHub |

---

## ğŸ—‚ï¸ Project Structure

```
databricks-sales-pipeline/
â”‚
â”œâ”€â”€ 01_Bronze.ipynb          # Raw data ingestion â†’ Delta table
â”œâ”€â”€ 02_Silver.ipynb          # Data cleaning & transformation
â”œâ”€â”€ 03_Gold.ipynb            # Aggregations & business metrics
â”œâ”€â”€ 04_Delta_Features.ipynb  # Delta Lake features (Time Travel, Optimize, Vacuum)
â””â”€â”€ README.md
```

---

## ğŸ—ï¸ Architecture

```
Raw JSON Data (retail-org/sales_orders)
            â”‚
            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    BRONZE    â”‚  â†’ Raw data saved as Delta table (no changes)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    SILVER    â”‚  â†’ Cleaned, flattened, enriched data
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     GOLD     â”‚  â†’ Aggregated business-ready metrics
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  DASHBOARD   â”‚  â†’ Visual insights (Databricks SQL)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   WORKFLOW   â”‚  â†’ Automated scheduled pipeline
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ““ Notebooks

### 01_Bronze â€” Raw Ingestion
- Reads raw JSON sales data from `/databricks-datasets/retail-org/sales_orders/`
- Creates `sales_db` database in Hive Metastore
- Saves raw data as-is to `sales_db.bronze_sales_orders` Delta table
- No transformations â€” preserves original data as source of truth

### 02_Silver â€” Cleaning & Transformation
- Loads from Bronze Delta table
- Explodes nested `ordered_products` array (one row per product per order)
- Converts Unix timestamp to readable datetime using `from_unixtime`
- Handles null and empty values safely using `nullif`
- Adds calculated column: `line_total = price Ã— quantity`
- Drops duplicates and null records
- Saves to `sales_db.silver_sales_orders` Delta table

### 03_Gold â€” Aggregations
Creates 3 business-ready Gold tables:

| Table | Description |
|-------|-------------|
| `gold_revenue_by_customer` | Total revenue and order count per customer |
| `gold_revenue_by_product` | Total revenue and units sold per product |
| `gold_revenue_by_month` | Monthly revenue trend over time |

### 04_Delta_Features â€” Delta Lake Exploration
- `DESCRIBE HISTORY` â€” view full transaction log of a table
- `VERSION AS OF` â€” query historical versions (Time Travel)
- `OPTIMIZE` â€” compact small files for better query performance
- `VACUUM` â€” remove old files no longer needed by Delta

---

## ğŸ—„ï¸ Database & Tables

```
sales_db
â”œâ”€â”€ bronze_sales_orders        (raw)
â”œâ”€â”€ silver_sales_orders        (clean)
â”œâ”€â”€ gold_revenue_by_customer   (aggregated)
â”œâ”€â”€ gold_revenue_by_product    (aggregated)
â””â”€â”€ gold_revenue_by_month      (aggregated)
```

---

## ğŸ“Š Dashboard

Built in **Databricks SQL Lakeview Dashboard** with 3 visualizations:
- ğŸ“ˆ **Line Chart** â€” Monthly Revenue Trend (`gold_revenue_by_month`)
- ğŸ“Š **Bar Chart** â€” Top 10 Products by Revenue (`gold_revenue_by_product`)
- ğŸ“Š **Bar Chart** â€” Top 10 Customers by Revenue (`gold_revenue_by_customer`)

---

## âš™ï¸ Workflow (Sales Pipeline Job)

Automated pipeline with 3 tasks running in sequence:

```
Bronze Task â†’ Silver Task â†’ Gold Task
```

Each task depends on the previous one completing successfully. Can be triggered manually or on a schedule.

---

## ğŸ”‘ Key Databricks Concepts Covered

- âœ… Cluster creation and management
- âœ… Notebook development (Python + SQL magic commands)
- âœ… PySpark DataFrames â€” read, transform, write
- âœ… Delta Lake â€” ACID transactions, transaction log
- âœ… Delta Time Travel â€” `VERSION AS OF`
- âœ… Medallion Architecture â€” Bronze, Silver, Gold
- âœ… Hive Metastore â€” databases and managed tables
- âœ… Databricks SQL â€” queries and visualizations
- âœ… Lakeview Dashboards
- âœ… Workflows & Jobs â€” multi-task orchestration
- âœ… Repos â€” Git integration with GitHub
- âœ… DBFS â€” Databricks File System

---

## ğŸš€ How to Run

1. Clone this repo into your Databricks workspace via **Repos**
2. Create a cluster (any single-node cluster works)
3. Run notebooks in order: `01_Bronze` â†’ `02_Silver` â†’ `03_Gold` â†’ `04_Delta_Features`
4. Or use the **Sales Pipeline** Workflow job to run all automatically

---

## ğŸ‘¤ Author

**Zeeshan Ahmed**  
Built on Databricks Community Edition â€” February 2026
